{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "886fcb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbb9bba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTRINSIC Matrix K (3X4) that transfers 3D world to 2D image\n",
    "f_x = 150\n",
    "f_y = 100\n",
    "o_x = 10\n",
    "o_y = 10\n",
    "\n",
    "# use 3X3 K to find inverse easier\n",
    "\n",
    "K = np.array([[f_x, 0, o_x],\n",
    "             [0, f_y, o_y],\n",
    "             [0, 0, 1]])\n",
    "K_inv = np.linalg.inv(K)\n",
    "# depth of point lambda\n",
    "# THIS IS UNKOWN\n",
    "\n",
    "# lda = Z' of homogenous coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2bb917f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,1,1] projected:  [92.74151730121204, 22.357522879713578]\n",
      "[2,3,5] projected:  [110.60867434207991, 35.24034845063944]\n",
      "[17,29,22] projected:  [190.76059321610018, 180.20928324555723]\n"
     ]
    }
   ],
   "source": [
    "# FOR TESTING ONLY!\n",
    "# training data calculation, used for input above to train the projection matrix\n",
    "\n",
    "theta = m.pi/6\n",
    "phi = m.pi/3\n",
    "psi = m.pi/4\n",
    "\n",
    "R_x = [[1, 0, 0], \n",
    "       [0, m.cos(theta), -m.sin(theta)],\n",
    "       [0, m.sin(theta), m.cos(theta)]]\n",
    "\n",
    "R_y = [[m.cos(phi), 0, m.sin(phi)],\n",
    "      [0, 1, 0],\n",
    "      [-m.sin(phi), 0, m.cos(phi)]]\n",
    "\n",
    "R_z = [[m.cos(psi), -m.sin(psi), 0],\n",
    "      [m.sin(psi), m.cos(psi), 0],\n",
    "      [0, 0, 1]]\n",
    "R_test = np.dot(R_z, np.dot(R_y, R_x))\n",
    "\n",
    "t_test = [10, 1, 20]\n",
    "\n",
    "#lda = 3\n",
    "# roate 30 deg row, 60 deg pitch, 45 deg yaw, translate [10,1,20]\n",
    "\n",
    "# converting homogeneous coordinate to cartesian coordinate\n",
    "def toCartes(a):\n",
    "    return [a[0]/a[2], a[1]/a[2]]\n",
    "\n",
    "# function representing the overall projection of 3D lidar image to 2D camera image\n",
    "def project(x):\n",
    "    return toCartes(np.dot(K, (np.dot(R_test, x)+t_test)))\n",
    "\n",
    "print(\"[1,1,1] projected: \", project([1,1,1]))\n",
    "print(\"[2,3,5] projected: \", project([2,3,5]))\n",
    "print(\"[17,29,22] projected: \", project([17,29,22]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10ee3fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR TESTING ONLY!\n",
    "# enter at minimum 9 sets of u, v, X, Y, Z training data\n",
    "# based on the camera parameter K above\n",
    "# X, Y, Z data inputted here, then u and v data points caculated using the code block above\n",
    "# in this specific training set, roate 60 deg row, 45 deg pitch, 30 deg yaw, then transform [2,-2,3]\n",
    "\n",
    "X1 = 1; Y1 = 1; Z1 = 1 ; u1 = project([X1,Y1,Z1])[0]; v1 = project([X1,Y1,Z1])[1]\n",
    "X2 = 2; Y2 = 3; Z2 = 5; u2 = project([X2,Y2,Z2])[0]; v2 = project([X2,Y2,Z2])[1]\n",
    "X3 = 17; Y3 = 29; Z3 = 22; u3 = project([X3,Y3,Z3])[0]; v3 = project([X3,Y3,Z3])[1]\n",
    "X4 = 1; Y4 = 4; Z4 = 12; u4 = project([X4,Y4,Z4])[0]; v4 = project([X4,Y4,Z4])[1]\n",
    "X5 = 10; Y5 = 100; Z5 = 10; u5 = project([X5,Y5,Z5])[0]; v5 = project([X5,Y5,Z5])[1]\n",
    "X6 = 100; Y6 = 290; Z6 = 149; u6 = project([X6,Y6,Z6])[0]; v6 = project([X6,Y6,Z6])[1]\n",
    "X7 = 170; Y7 = 130; Z7 = 23; u7 = project([X7,Y7,Z7])[0]; v7 = project([X7,Y7,Z7])[1]\n",
    "X8 = 7; Y8 = 79; Z8 = 201; u8 = project([X8,Y8,Z8])[0]; v8 = project([X8,Y8,Z8])[1]\n",
    "X9 = 52; Y9 = 4; Z9 = 122; u9 = project([X9,Y9,Z9])[0]; v9 = project([X9,Y9,Z9])[1]\n",
    "\n",
    "X10 = 19; Y10 = 35; Z10 = 1 ; u10 = project([X10,Y10,Z10])[0]; v10 = project([X10,Y10,Z10])[1]\n",
    "X11 = 24; Y11 = 300; Z11 = 1 ; u11 = project([X11,Y11,Z11])[0]; v11 = project([X11,Y11,Z11])[1]\n",
    "X12 = 208; Y12 = 3; Z12 = 140; u12 = project([X12,Y12,Z12])[0]; v12 = project([X12,Y12,Z12])[1]\n",
    "X13 = 170; Y13 = 29; Z13 = 22; u13 = project([X13,Y13,Z13])[0]; v13 = project([X13,Y13,Z13])[1]\n",
    "X14 = 45; Y14 = 278; Z14 = 237; u14 = project([X14,Y14,Z14])[0]; v14 = project([X14,Y14,Z14])[1]\n",
    "X15 = 110; Y15 = 10; Z15 = 102; u15 = project([X15,Y15,Z15])[0]; v15 = project([X15,Y15,Z15])[1]\n",
    "X16 = 1; Y16 = 290; Z16 = 170; u16 = project([X16,Y16,Z16])[0]; v16 = project([X16,Y16,Z16])[1]\n",
    "X17 = 17; Y17 = 13; Z17 = 223; u17 = project([X17,Y17,Z17])[0]; v17 = project([X17,Y17,Z17])[1]\n",
    "X18 = 270; Y18 = 79; Z18 = 2; u18 = project([X18,Y18,Z18])[0]; v18 = project([X18,Y18,Z18])[1]\n",
    "X19 = 2; Y19 = 34; Z19 = 222; u19 = project([X19,Y19,Z19])[0]; v19 = project([X19,Y19,Z19])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6d31f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninput = [[],[],[],[]...] length i\\n\\nW_lst = [] # use list for flexibility\\nfor i in range len(input):\\n    a = input[i]\\n    W_lst.append([a[0]*a[2], a[0]*a[3], a[0]*a[4], a[1]*a[2], a[1]*a[3], a[1]*a[4], a[2], a[3], a[4]])\\n    \\nW = np.array(W_lst)\\n    \\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input parameter when using actual camera and lidar points\n",
    "# input as 2d list in format of [[ui,vi,Xi,Yi,Zi]...], where u,v are camera points, X,Y,Z are lidar points\n",
    "# automatic input?\n",
    "\n",
    "'''\n",
    "input = [[],[],[],[]...] length i\n",
    "\n",
    "def make_W(input):\n",
    "    W_lst = [] # use list for flexibility\n",
    "    for i in range len(input):\n",
    "        a = input[i]\n",
    "        W_lst.append([a[0]*a[2], a[0]*a[3], a[0]*a[4], a[1]*a[2], a[1]*a[3], a[1]*a[4], a[2], a[3], a[4]])\n",
    "    \n",
    "    W = np.array(W_lst)\n",
    "    \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8aff540e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:  [[ 20.6044919   -1.81225724  15.94969534]\n",
      " [-76.61203266  13.39621036 -60.38048629]\n",
      " [ -6.47164432   0.2363181   -4.95582336]]\n"
     ]
    }
   ],
   "source": [
    "# Using SVD to solve for 3D -> 2D fundamental matrix F, where F = K^-1^T * E, DIFFERENT from camera matching F matrix\n",
    "# now we have a possibly full rank F matrix approximation, call it F_fre\n",
    "# then further make F more precise by only using first 2 singular values of F's SVD, since F has rank=2\n",
    "# decompose E = K^T * F\n",
    "# concept: https://web.stanford.edu/class/cs231a/course_notes/03-epipolar-geometry.pdf\n",
    "W = np.array([[u1*X1, u1*Y1, u1*Z1, v1*X1, v1*Y1, v1*Z1, X1, Y1, Z1],\n",
    "             [u2*X2, u2*Y2, u2*Z2, v2*X2, v2*Y2, v2*Z2, X2, Y2, Z2],\n",
    "             [u3*X3, u3*Y3, u3*Z3, v3*X3, v3*Y3, v3*Z3, X3, Y3, Z3],\n",
    "             [u4*X4, u4*Y4, u4*Z4, v4*X4, v4*Y4, v4*Z4, X4, Y4, Z4],\n",
    "             [u5*X5, u5*Y5, u5*Z5, v5*X5, v5*Y5, v5*Z5, X5, Y5, Z5],\n",
    "             [u6*X6, u6*Y6, u6*Z6, v6*X6, v6*Y6, v6*Z6, X6, Y6, Z6],\n",
    "             [u7*X7, u7*Y7, u7*Z7, v7*X7, v7*Y7, v7*Z7, X7, Y7, Z7],\n",
    "             [u8*X8, u8*Y8, u8*Z8, v8*X8, v8*Y8, v8*Z8, X8, Y8, Z8],\n",
    "             [u9*X9, u9*Y9, u9*Z9, v9*X9, v9*Y9, v9*Z9, X9, Y9, Z9],\n",
    "             [u10*X10, u10*Y10, u10*Z10, v10*X10, v10*Y10, v10*Z10, X10, Y10, Z10],\n",
    "             [u11*X11, u11*Y11, u11*Z11, v11*X11, v11*Y11, v11*Z11, X11, Y11, Z11],\n",
    "             [u12*X12, u12*Y12, u12*Z12, v12*X12, v12*Y12, v12*Z12, X12, Y12, Z12],\n",
    "             [u13*X13, u13*Y13, u13*Z13, v13*X13, v13*Y13, v13*Z13, X13, Y13, Z13],\n",
    "             [u14*X14, u14*Y14, u14*Z14, v14*X14, v14*Y14, v14*Z14, X14, Y14, Z14],\n",
    "             [u15*X15, u15*Y15, u15*Z15, v15*X15, v15*Y15, v15*Z15, X15, Y15, Z15],\n",
    "             [u16*X16, u16*Y16, u16*Z16, v16*X16, v16*Y16, v16*Z16, X16, Y16, Z16],\n",
    "             [u17*X17, u17*Y17, u17*Z17, v17*X17, v17*Y17, v17*Z17, X17, Y17, Z17],\n",
    "             [u18*X18, u18*Y18, u18*Z18, v18*X18, v18*Y18, v18*Z18, X18, Y18, Z18],\n",
    "             [u19*X19, u19*Y19, u19*Z19, v19*X19, v19*Y19, v19*Z19, X19, Y19, Z19]])\n",
    "# input: W\n",
    "# output: essential matrix E\n",
    "def get_essential_matrix(W):\n",
    "    f = np.linalg.svd(W)[2][-1] # use SVD to estimate fundamental matrix components\n",
    "\n",
    "    # reshape to 3x3 to get Full Rank Estimate of Fundamental matrix\n",
    "    F_fre = np.array([[f[0], f[1], f[2]],\n",
    "                 [f[3], f[4], f[5]],\n",
    "                 [f[6], f[7], f[8]]])\n",
    "\n",
    "    sig1 = np.linalg.svd(F_fre)[1][0]\n",
    "    sig2 = np.linalg.svd(F_fre)[1][0]\n",
    "\n",
    "    rank_2_sig = np.array([[sig1, 0, 0],\n",
    "                      [0, sig2, 0],\n",
    "                      [0, 0, 0]])\n",
    "\n",
    "    # get best estimate of rank 2 fundamental matrix (3D -> 2D)\n",
    "    F = np.dot(np.linalg.svd(F_fre)[0], np.dot(rank_2_sig, np.linalg.svd(F_fre)[2]))\n",
    "\n",
    "    E = np.dot(np.transpose(K), F)\n",
    "    return E\n",
    "\n",
    "#print(\"F: \", F)\n",
    "E = get_essential_matrix(W)\n",
    "print(\"E: \", E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00bb0c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R1:  [[ 0.35355339 -0.30618622  0.88388348]\n",
      " [ 0.35355339  0.91855865  0.1767767 ]\n",
      " [-0.8660254   0.25        0.4330127 ]]\n",
      "R2:  [[-0.88973785  0.420226   -0.1782601 ]\n",
      " [-0.40717184 -0.90715468 -0.10621436]\n",
      " [-0.20634352 -0.02192044  0.97823404]]\n",
      "t1:  [0.44676705 0.04467671 0.8935341 ]\n",
      "t2:  [-0.44676705 -0.04467671 -0.8935341 ]\n"
     ]
    }
   ],
   "source": [
    "# Recover R, T from essential matrix E = T_x* R, where T_x = [[0, -tz, ty],[tz,0,-tx],[-ty,tx,0]]\n",
    "# take SVD of E = U*[[1,0,0],[0,1,0],[0,0,0]]*V^T \n",
    "# E also equals T_x*R, notice T_x = [u1, u2, t]*[[0,1,0],[-1,0,0],[0,0,0]]*[u1, u2, t]^T since U is orthanormal\n",
    "# let R = U*Y*V^T, so E = [u1, u2, t]*[[0,1,0],[-1,0,0],[0,0,0]]*[u1, u2, t]^T * U * Y * V^T = U*[[1,0,0],[0,1,0],[0,0,0]]*V^T \n",
    "# do some canceling terms we got Y = [[0,-1,0],[1,0,0],[0,0,1]] or its transpose, t = +-u3\n",
    "# concept: https://inst.eecs.berkeley.edu/~ee290t/fa19/lectures/lecture10-3-decomposing-F-matrix-into-Rotation-and-Translation.pdf\n",
    "\n",
    "# input: Essential Matrix E\n",
    "# output: 2 options of Rotation matrix R and 2 options of unscaled translation vector t \n",
    "def recover_R_T(E): \n",
    "    U, SIG, VT = np.linalg.svd(E)\n",
    "\n",
    "    # 2 possibilities of Y\n",
    "    Y1 = np.array([[0, -1, 0],\n",
    "                  [1, 0, 0],\n",
    "                  [0, 0, 1]])\n",
    "    Y2 = np.transpose(Y1)\n",
    "    #print(U)\n",
    "\n",
    "    # 2 possibilities each for R and t, gave 4 possible projection matrices\n",
    "    R1 = np.dot(U, np.dot(Y1, VT))\n",
    "    R2 = np.dot(U, np.dot(Y2, VT))\n",
    "    t1 = np.array([U[0][2], U[1][2], U[2][2]])\n",
    "    t2 = -t1\n",
    "    \n",
    "    return R1, R2, t1, t2\n",
    "\n",
    "R1, R2, t1, t2 = recover_R_T(E)\n",
    "print(\"R1: \", R1)\n",
    "print(\"R2: \", R2)\n",
    "print(\"t1: \", t1)\n",
    "print(\"t2: \", t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ece4a04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'R1_t1': 12, 'R1_t2': 12, 'R2_t1': 13, 'R2_t2': 14}\n",
      "[[-0.88973785  0.420226   -0.1782601 ]\n",
      " [-0.40717184 -0.90715468 -0.10621436]\n",
      " [-0.20634352 -0.02192044  0.97823404]]\n",
      "[0.44676705 0.04467671 0.8935341 ]\n",
      "[-0.44676705 -0.04467671 -0.8935341 ]\n"
     ]
    }
   ],
   "source": [
    "# 03/02: THIS FUNCTION IS NOT RELIABLE! choose R,t manually until this is fixed\n",
    "\n",
    "# Disambiguate the 4 possibilities: the reconstructed camera origin must be IN FRONT of the image\n",
    "# IF the result seems very wrong in the disambiguate matrix, choose R, t that make sense MANUALLY\n",
    "\n",
    "# use X, Y, Z data points to test if the Z coordinate is possitive when projected\n",
    "xyz_set = np.array([[X1, Y1, Z1], [X2, Y2, Z2], [X3, Y3, Z3], \n",
    "                   [X4, Y4, Z4], [X5, Y5, Z5], [X6, Y6, Z6], \n",
    "                   [X7, Y7, Z7], [X8, Y8, Z8], [X9, Y9, Z9], [X10, Y10, Z10],\n",
    "                   [X11, Y11, Z11], [X12, Y12, Z12], [X13, Y13, Z13],\n",
    "                   [X14, Y14, Z14], [X15, Y15, Z15], [X16, Y16, Z16],\n",
    "                   [X17, Y17, Z17], [X18, Y18, Z18], [X19, Y19, Z19]])\n",
    "\n",
    "# input: the 2 options for R and 2 options for t, set of known X,Y,Z values for training\n",
    "def disambiguate(R1, R2, t1, t2, xyz_set):\n",
    "    r1_3 = R1[2]   \n",
    "    r2_3 = R2[2]\n",
    "\n",
    "    # the best camera configuration is the R and t combination that result in camera origin in front of image for MOST data points\n",
    "\n",
    "    score_R1_t1 = 0\n",
    "    score_R1_t2 = 0\n",
    "    score_R2_t1 = 0\n",
    "    score_R2_t2 = 0\n",
    "\n",
    "    for xyz in xyz_set:\n",
    "        if (np.dot(r1_3, ([xyz[0], xyz[1], xyz[2]] - t1)) > 0):\n",
    "            score_R1_t1 += 1\n",
    "        if (np.dot(r1_3, ([xyz[0], xyz[1], xyz[2]] - t2)) > 0):\n",
    "            score_R1_t2 += 1\n",
    "        if (np.dot(r2_3, ([xyz[0], xyz[1], xyz[2]] - t1)) > 0):\n",
    "            score_R2_t1 += 1\n",
    "        if (np.dot(r2_3, ([xyz[0], xyz[1], xyz[2]] - t2)) > 0):\n",
    "            score_R2_t2 += 1\n",
    "    \n",
    "    score_dict = {\"R1_t1\":score_R1_t1, \"R1_t2\":score_R1_t2, \"R2_t1\":score_R2_t1, \"R2_t2\":score_R2_t2}\n",
    "    print(score_dict)\n",
    "    actual_RT = max(score_dict)\n",
    "    R = np.array([])\n",
    "    t = np.array([])\n",
    "    if (actual_RT == \"R1_t1\"):\n",
    "        R = R1\n",
    "        t = t1\n",
    "    elif (actual_RT == \"R1_t2\"):\n",
    "        R = R1\n",
    "        t = t2\n",
    "    elif (actual_RT == \"R2_t1\"):\n",
    "        R = R2\n",
    "        t = t1\n",
    "    else:\n",
    "        R = R2\n",
    "        t = t2\n",
    "    return R, t\n",
    "\n",
    "R, t = disambiguate(R1, R2, t1, t2, xyz_set)\n",
    "print(R)\n",
    "print(t1)\n",
    "print(t2)\n",
    "# sometimes -R gives correct angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f7ab5cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R1, R2, -R1, -R2 results, respectively: \n",
      "\n",
      "x-rotation (roll) =  29.999999999999172\n",
      "y-rotation (pitch) =  59.999999999999766\n",
      "z-rotation (yaw) =  44.99999999999936\n",
      "\n",
      "x-rotation (roll) =  -1.283679111608276\n",
      "y-rotation (pitch) =  11.908158785182767\n",
      "z-rotation (yaw) =  -155.40968758965568\n",
      "\n",
      "x-rotation (roll) =  -150.00000000000082\n",
      "y-rotation (pitch) =  -59.999999999999766\n",
      "z-rotation (yaw) =  -135.00000000000063\n",
      "\n",
      "x-rotation (roll) =  178.71632088839172\n",
      "y-rotation (pitch) =  -11.908158785182767\n",
      "z-rotation (yaw) =  24.590312410344335\n"
     ]
    }
   ],
   "source": [
    "yaw = m.degrees(m.atan2(R[1][0], R[0][0]))\n",
    "pitch = m.degrees(m.atan2(-R[2][0], m.sqrt(R[2][1]**2 + R[2][2]**2)))\n",
    "roll = m.degrees(m.atan2(R[2][1], R[2][2]))\n",
    "\n",
    "# make sure all angles above 0, manually choose R in case disambiguate failed: \n",
    "# guide to manually select R,t\n",
    "\n",
    "print(\"R1, R2, -R1, -R2 results, respectively: \")\n",
    "for R in np.array([R1, R2, -R1, -R2]):\n",
    "    yaw = m.degrees(m.atan2(R[1][0], R[0][0]))\n",
    "    pitch = m.degrees(m.atan2(-R[2][0], m.sqrt(R[2][1]**2 + R[2][2]**2)))\n",
    "    roll = m.degrees(m.atan2(R[2][1], R[2][2]))\n",
    "    print()\n",
    "    print(\"x-rotation (roll) = \", roll) # actual roll 60\n",
    "    print(\"y-rotation (pitch) = \", pitch) # actual roll 45\n",
    "    print(\"z-rotation (yaw) = \", yaw) # actual yaw 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "45ce0a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R:  [[ 0.35355339 -0.30618622  0.88388348]\n",
      " [ 0.35355339  0.91855865  0.1767767 ]\n",
      " [-0.8660254   0.25        0.4330127 ]]\n",
      "t:  [0.44676705 0.04467671 0.8935341 ]\n"
     ]
    }
   ],
   "source": [
    "# Here we choose R and t for this specific case:\n",
    "# here it seems like R1 is the most accurate approximation of actual angles of rotation\n",
    "# we know this since all rotation values are within 0-90 degrees\n",
    "R = R1\n",
    "# try finding the lamda and accurate t values\n",
    "# it seems like t1 is closer to the actual t vector: [10,1,20]\n",
    "t = t1\n",
    "print(\"R: \", R)\n",
    "print(\"t: \", t)\n",
    "\n",
    "# NOTICE this t vector here is off by a scale, but the proportion of translation is the same \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9ff92651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrected t: [10.  1. 20.]\n",
      "Z of homogenous coordinate, aka lambda: 19.816987298107037\n"
     ]
    }
   ],
   "source": [
    "# use any one u,v,X,Y,Z value to recover the real t, since the t value is scaled,\n",
    "# we want to find constant C to scale it back so t_real = t_previous_part * c\n",
    "# also recover lambda, the homogenous coordiante's Z value\n",
    "a = np.dot(K_inv, np.array([u1,v1,1]))\n",
    "b = np.dot(R, np.array([X1,Y1,Z1]))\n",
    "\n",
    "Jia = np.array([[a[0], -t[0]],\n",
    "               [a[1], -t[1]]])\n",
    "ming = np.array([b[0], b[1]])\n",
    "\n",
    "lda, C = np.linalg.solve(Jia, ming)\n",
    "\n",
    "t = C * t\n",
    "print(\"corrected t:\", t) # actual t recovered!!!\n",
    "print(\"Z of homogenous coordinate, aka lambda:\", lda) # this is Z'1, the depth factor after R[X,Y,Z]+t, or K_inv*[u,v,1]*lda\n",
    "# this lambda is specific to u1,v1,X1,Y1,Z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd765e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left hand side: [1837.85747037  443.05874692   19.8169873 ]\n",
      "right hand side: [1837.85747037  443.05874692   19.8169873 ]\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "# lda * [u,v,1]^T = K*(R*[X,Y,Z]^T+t)\n",
    "print(\"left hand side:\", lda * np.array([u1,v1,1]))\n",
    "print(\"right hand side:\", np.dot(K, (np.dot(R, np.array([X1,Y1,Z1]))+t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f549cd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 point method result:  [91.82797148917977, 343.2821396574136]\n",
      "actual P result:  [91.82797148918137, 343.2821396574106]\n"
     ]
    }
   ],
   "source": [
    "# test if the projection matrices calculated are accurate \n",
    "# result = [u,v] given [X,Y,Z]\n",
    "\n",
    "print(\"9 point method result: \", toCartes(np.dot(K, (np.dot(R, [60,287,121])+t))))\n",
    "\n",
    "print(\"actual P result: \", project([60,287,121]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "13f913d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# fix the disambiguate function so we don't have to manually select R,t \n",
    "    # what are the bounds of rotation and translation? how many degrees can we go? how far can we translate? \n",
    "    # can we translate to negative direction? if so need to find a way to disambiguate R and t\n",
    "# organize and reformat this file so it could better integrate with other people's work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fcdfde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec12f55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
